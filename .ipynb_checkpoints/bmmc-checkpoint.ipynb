{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1855ce9d-45d1-4fbc-b7bc-44c2d46ddc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def team_name(input_string):\n",
    "    \"\"\"\n",
    "    Strips the ranking component (a number in parentheses at the end) from the given string.\n",
    "    \"\"\"\n",
    "    # Use regex to match and strip \"(number)\" only if it appears at the end\n",
    "    return re.sub(r'\\s*\\(\\d+\\)$', '', input_string)\n",
    "\n",
    "# Examples\n",
    "assert team_name(\"UConn (6)\") == \"UConn\"\n",
    "assert team_name(\"North Carolina\") == \"North Carolina\"\n",
    "assert team_name(\"UConn (North) (9)\") == \"UConn (North)\"\n",
    "assert team_name(\"UConn (North)\") == \"UConn (North)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8596fd65-1ab1-4644-9a07-90ae62b9abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)  # Preserves function metadata\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Call the original function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Function '{func.__name__}' took {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc1ef67-b00d-4a55-b995-2cfefba7c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = \"Basketball_dataset.xlsx\"\n",
    "excel_file = pd.ExcelFile(file_name)\n",
    "\n",
    "team_metadata = excel_file.parse(sheet_name=\"Teams\")\n",
    "team_metadata[\"Team\"] = team_metadata[\"Team\"].apply(lambda s : s.strip())\n",
    "\n",
    "sheet_names = {\n",
    "    team_name(sheet_name) : sheet_name for sheet_name in excel_file.sheet_names[1:]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898bd015-d107-4829-9807-dce1d2acb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: Duke(13), Unable to identify team's 'real' name, they didn't play against any ranked opponents that we could identify\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Each row in our dataframe of all the games looks as follows:\n",
    "\n",
    "\n",
    "Team,Type,Opponent,For,Against\n",
    "\"\"\"\n",
    "def resolve_team_name(sheet_name):\n",
    "    \"\"\"\n",
    "    Resolve the true name of a team by examining ranked opponents' sheets\n",
    "    Why do we need this? UConn is represented by Connecticut in the opponent's table\n",
    "\n",
    "    Args:\n",
    "        sheet_name (str): The current sheet name.\n",
    "        ranked_teams (set): Set of ranked team names.\n",
    "        excel_file (pd.ExcelFile): The Excel file object.\n",
    "\n",
    "    Returns:\n",
    "        str: The resolved \"true name\" of the team.\n",
    "    \"\"\"\n",
    "    # Try to parse the current team's sheet\n",
    "    our_team_sheet = excel_file.parse(sheet_name=sheet_name)\n",
    "    opponents = our_team_sheet[\"Opponent\"].dropna().apply(team_name)\n",
    "\n",
    "    # Check if any opponent is a ranked team\n",
    "    for i,row in our_team_sheet.dropna().iterrows():\n",
    "        opponent_name = team_name(row[\"Opponent\"])\n",
    "        if opponent_name in sheet_names and sheet_names[opponent_name] in excel_file.sheet_names:\n",
    "          opponent_sheet = excel_file.parse(sheet_name=sheet_names[opponent_name])\n",
    "          target_row = opponent_sheet[opponent_sheet.apply(lambda r : r[\"Date\"] == row[\"Date\"], axis=1)]\n",
    "          if not target_row.empty:\n",
    "            # Extract the \"Team\" column from the opponent's perspective\n",
    "            resolved_name = target_row.iloc[0][\"Opponent\"]\n",
    "            return team_name(resolved_name)     \n",
    "\n",
    "    print(f\"Team: {sheet_name}, Unable to identify team's 'real' name, they didn't play against any ranked opponents that we could identify\")\n",
    "    return team_name(sheet_name)\n",
    "\n",
    "abbrev_to_team_name = {\n",
    "    team : resolve_team_name(sheet_names[team]) for team in sheet_names\n",
    "}\n",
    "team_names = set(abbrev_to_team_name.values())\n",
    "ranked_teams = team_names\n",
    "team_rank = {}\n",
    "for i,t in enumerate(excel_file.sheet_names[1:]):\n",
    "    team_rank[abbrev_to_team_name[team_name(t)]] = 1+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8d1009-7a2b-4f05-91d4-7c262fc3dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_basketball_sheets():\n",
    "    \"\"\"\n",
    "    Combine multiple sheets from an Excel file into a single DataFrame with filtering.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with columns Type, Team, Opponent, For, Against.\n",
    "    \"\"\"\n",
    "\n",
    "    combined_data = []\n",
    "\n",
    "    for sheet_name in excel_file.sheet_names[1:]:\n",
    "        team_data = excel_file.parse(sheet_name=sheet_name)\n",
    "\n",
    "        our_name = abbrev_to_team_name[team_name(sheet_name)]\n",
    "        team_data[\"Team\"] = our_name\n",
    "        team_data.rename(columns={\"Tm\": \"For\", \"Opp\": \"Against\"}, inplace=True)\n",
    "        team_data[\"Opponent\"] = team_data[\"Opponent\"].dropna().apply(team_name)\n",
    "    \n",
    "        team_data = team_data[[\"Date\", \"Type\", \"Team\", \"Opponent\", \"For\", \"Against\"]]\n",
    "        combined_data.append(team_data)\n",
    "\n",
    "    # Concatenate all data into a single DataFrame\n",
    "    df = pd.concat(combined_data, ignore_index=True).dropna()\n",
    "\n",
    "    ### Drop duplicates (just add columns that uniquely identify a game )\n",
    "\n",
    "    # Ensure consistent ordering for Team/Opponent and For/Against\n",
    "    df[\"Team_Ordered\"] = df[[\"Team\", \"Opponent\"]].min(axis=1)\n",
    "    df[\"Opponent_Ordered\"] = df[[\"Team\", \"Opponent\"]].max(axis=1)\n",
    "    df[\"For_Ordered\"] = df[[\"For\", \"Against\"]].min(axis=1)\n",
    "    df[\"Against_Ordered\"] = df[[\"For\", \"Against\"]].max(axis=1)\n",
    "\n",
    "    # Drop duplicates based on ordered columns\n",
    "    df = df.drop_duplicates(subset=[\"Team_Ordered\", \"Opponent_Ordered\", \"For_Ordered\", \"Against_Ordered\", \"Type\", \"Date\"])\n",
    "\n",
    "    # Drop the helper columns\n",
    "    df = df.drop(columns=[\"Team_Ordered\", \"Opponent_Ordered\", \"For_Ordered\", \"Against_Ordered\"])\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "all_games = combine_basketball_sheets()\n",
    "\n",
    "# INCLUDES NON_RANKED_TEAMS! PLEASE USE THIS ONE\n",
    "all_teams = set(all_games[\"Team\"]).union(set(all_games[\"Opponent\"]))\n",
    "# UNIQUE ID FOR EACH TEAM\n",
    "id_to_team = { i:team for i,team in enumerate(all_teams)}\n",
    "team_to_id = { team:i for i,team in enumerate(all_teams)}\n",
    "num_teams = len(all_teams)\n",
    "\n",
    "all_games[\"TeamId\"] = all_games[\"Team\"].apply(lambda r: team_to_id[r])\n",
    "all_games[\"OpponentId\"] = all_games[\"Opponent\"].apply(lambda r : team_to_id[r])\n",
    "all_games[\"ObservedDiff\"] = all_games.apply(lambda r: r[\"For\"] - r[\"Against\"], axis=1)\n",
    "all_games['Date'] = pd.to_datetime(all_games['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78288504-d016-4f33-9f6f-e1a4caf333da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "def games_of(team_name, all_games):\n",
    "  games_by = all_games[all_games.apply(lambda r: r[\"Team\"] == team_name or r[\"Opponent\"] == team_name, axis=1)]\n",
    "  #print(games_by)\n",
    "  def normalize_game(row):\n",
    "    if row[\"Team\"] == team_name:\n",
    "      return row  # No changes needed\n",
    "    else:\n",
    "            # Swap Team and Opponent, For and Against\n",
    "      return {\n",
    "                \"Type\": row[\"Type\"],\n",
    "                \"Team\": row[\"Opponent\"],\n",
    "                \"Opponent\": row[\"Team\"],\n",
    "                \"For\": row[\"Against\"],\n",
    "                \"Against\": row[\"For\"],\n",
    "                \n",
    "            }\n",
    "\n",
    "    # Apply normalization to ensure Team == team_name\n",
    "  res = games_by.apply(normalize_game, axis=1, result_type=\"expand\")\n",
    "  res[\"TeamId\"] = res[\"Team\"].apply(lambda r: team_to_id[r])\n",
    "  res[\"OpponentId\"] = res[\"Opponent\"].apply(lambda r : team_to_id[r])\n",
    "  res[\"ObservedDiff\"] = res.apply(lambda r: r[\"For\"] - r[\"Against\"], axis=1)\n",
    "\n",
    "  return res\n",
    "\n",
    "games_of_cached = {\n",
    "    id : games_of(team, all_games) for id,team in id_to_team.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e123c1a-343e-4507-bcfe-44e76445c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def more_wins_model(all_games):\n",
    "  return {\n",
    "      team : sum(1 for _,game in games_of(team).iterrows() if game[\"For\"] > game[\"Against\"]) for team in all_teams\n",
    "  }\n",
    "\n",
    "import random\n",
    "\n",
    "def random_model(all_games):\n",
    "  return {\n",
    "      team : random.uniform(0, 1) for team in all_teams\n",
    "  }\n",
    "\n",
    "def higher_rank_model(all_games):\n",
    "    return { team : -team_rank.get(team, float('inf')) for team in all_teams\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7899c0b8-3c7d-4b8e-96d1-0f2ec4418c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_wins_over(all_games):\n",
    "    wins_over = np.zeros((num_teams, num_teams))\n",
    "    for _, r in all_games.iterrows():\n",
    "        i,j = team_to_id[r[\"Team\"]], team_to_id[r[\"Opponent\"]]\n",
    "        if r[\"For\"] > r[\"Against\"]:\n",
    "            wins_over[(i,j)] += 1\n",
    "        else:\n",
    "            wins_over[(j,i)] += 1\n",
    "    return wins_over\n",
    "\n",
    "def compute_point_difference(all_games):\n",
    "    point_difference = np.zeros((num_teams, num_teams))\n",
    "    for _, r in all_games.iterrows():\n",
    "        i,j = team_to_id[r[\"Team\"]], team_to_id[r[\"Opponent\"]]\n",
    "        diff = r[\"For\"] - r[\"Against\"]\n",
    "        point_difference[(i,j)] += diff\n",
    "        point_difference[(j,i)] += diff\n",
    "    return point_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8c6d9a-4427-4619-98cc-02facbc02470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "@timeit\n",
    "def bradley_terry(all_games):\n",
    "    team_count = num_teams\n",
    "    win_diff_matrix = compute_wins_over(all_games)  # Should return a sparse matrix format like CSR\n",
    "    \n",
    "    win_diff_matrix = csr_matrix(win_diff_matrix)  # Ensure it's in sparse format\n",
    "\n",
    "    def next_strengths(prior):\n",
    "        # Compute denom: dense because it depends on `prior`\n",
    "        denom = prior[:, None] + prior[None, :]  # Shape: (team_count, team_count)\n",
    "\n",
    "        # Sparse element-wise operations\n",
    "        numer = win_diff_matrix.multiply(prior[None, :] / denom)  # Sparse multiply\n",
    "        denom_update = win_diff_matrix.T.multiply(1 / denom)  # Sparse transpose and multiply\n",
    "\n",
    "        # Sum rows/columns using efficient sparse matrix methods\n",
    "        numer_sum = np.array(numer.sum(axis=1)).ravel()  # Convert sparse result to dense\n",
    "        denom_sum = np.array(denom_update.sum(axis=1)).ravel()\n",
    "\n",
    "        # Ensure denom_sum is safe for division\n",
    "        denom_sum = np.maximum(denom_sum, 1e-6)\n",
    "\n",
    "        next_strengths = numer_sum / denom_sum\n",
    "        return np.maximum(next_strengths, 1e-7)\n",
    "\n",
    "    curr_guess = np.ones(team_count)\n",
    "    num_iterations = 10_000\n",
    "\n",
    "    # Iterative update\n",
    "    for _ in range(num_iterations):\n",
    "        curr_guess = next_strengths(curr_guess)\n",
    "\n",
    "    return {id_to_team[i]: curr_guess[i] for i in range(team_count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e47d1d0-5309-46c9-b6ed-ce1350099222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "@timeit\n",
    "def parametric_estimation(all_games):\n",
    "    team_count = num_teams  # Total number of teams\n",
    "    total_num_games = all_games.shape[0]  # Total number of games\n",
    "    max_point_differential = 20\n",
    "    diff = (all_games[\"For\"] - all_games[\"Against\"]).clip(upper=10)\n",
    "\n",
    "    # Apply the logarithmic scaling with sign preservation\n",
    "    #observed_diff = diff\n",
    "    #diff.apply(lambda x: np.sign(x) * np.log(abs(x) + 1))\n",
    "    observed_diff = diff\n",
    "\n",
    "\n",
    "    loss_function_results = []\n",
    "\n",
    "    def next_sigma(strength):\n",
    "        \"\"\"\n",
    "        Returns sigma_partial, where\n",
    "\n",
    "        sigma_partial = \\sqrt{\\sum_{game \\in Games} (score[i] - score[j] - (strength[i] - strength[j]))^2 / total_num_games}\n",
    "\n",
    "        and strength is an array\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the predicted score differential\n",
    "        predicted_diff = strength[all_games[\"TeamId\"]] - strength[all_games[\"OpponentId\"]]\n",
    "        \n",
    "        # Compute the squared residuals\n",
    "        squared_residuals = (observed_diff - predicted_diff) ** 2\n",
    "        \n",
    "        # Compute sigma_partial\n",
    "        return np.sqrt(np.sum(squared_residuals) / total_num_games)\n",
    "\n",
    "    def strength_partial(strength, sigma, p):\n",
    "        \"\"\"\n",
    "        Returns the partial derivative of the strength of team p, where strength is an array and sigma is a constant\n",
    "\n",
    "        where delta_{i,j} = {-1 if i == p, 1 if j == p, and 0 otherwise}\n",
    "\n",
    "        returns -1/\\sigma^2 * \\sum_{game \\in Games}{delta(i,j) * (ObservedDiff - (strength[i] - strength[j]))}\n",
    "        \"\"\"\n",
    "        # Compute the predicted score differential\n",
    "        predicted_diff = strength[all_games[\"TeamId\"]] - strength[all_games[\"OpponentId\"]]\n",
    "        \n",
    "        # Compute delta(i, j) for each game\n",
    "        delta = np.where(all_games[\"TeamId\"] == p, -1, np.where(all_games[\"OpponentId\"] == p, 1, 0))\n",
    "        \n",
    "        # Compute the partial derivative\n",
    "        residuals = observed_diff - predicted_diff\n",
    "        return (-1 / sigma**2) * np.sum(delta * residuals)\n",
    "\n",
    "    def loss_function(strength, sigma):\n",
    "        \"\"\"\n",
    "        Returns the value of \n",
    "\n",
    "        -1/2 \\sum_{game \\in Games}(ln(2\\pi \\sigma^2) + \\frac{(game[\"ObservedDiff\"] - strength[i] - strength[j])**2}{\\sigma**2})\n",
    "        \"\"\"\n",
    "        # Compute the predicted score differential\n",
    "        predicted_diff = strength[all_games[\"TeamId\"]] - strength[all_games[\"OpponentId\"]]\n",
    "        \n",
    "        # Compute the squared residuals\n",
    "        squared_residuals = (observed_diff - predicted_diff) ** 2\n",
    "        \n",
    "        # Compute the log-likelihood loss\n",
    "        return (-1 / 2) * np.sum(\n",
    "            np.log(2 * np.pi * sigma**2) + (squared_residuals / sigma**2)\n",
    "        )\n",
    "\n",
    "    def compute_next_parameters(sigma, team_strengths, learning_rate):\n",
    "\n",
    "        current_loss = loss_function(team_strengths, sigma)\n",
    "        loss_function_results.append(current_loss)\n",
    "    \n",
    "        strength_grads = np.array([strength_partial(team_strengths, sigma, p) for p in range(len(team_strengths))])\n",
    "        # print(strength_grads)\n",
    "\n",
    "        sigma_new = next_sigma(team_strengths)\n",
    "        team_strengths_new = team_strengths + (learning_rate * strength_grads)\n",
    "\n",
    "        new_loss = loss_function(team_strengths_new, sigma_new)\n",
    "    \n",
    "        # learning_rate *= 0.99\n",
    "        return sigma_new, team_strengths_new, learning_rate\n",
    "\n",
    "    sigma, strengths, learning_rate = 1, np.zeros(num_teams), 1\n",
    "\n",
    "    iterations = 250\n",
    "    for _ in range(iterations):\n",
    "        sigma, strengths, learning_rate = compute_next_parameters(sigma, strengths, learning_rate)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(loss_function_results)\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # show results from the iterations\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return sigma, {id_to_team[i]: strengths[i] for i in range(team_count)}\n",
    "\n",
    "def parametric_estimation_prod(all_games):\n",
    "    sigma, strengths = parametric_estimation(all_games)\n",
    "    return strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840312b8-1b82-410a-8c03-6c27780e1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train on the preseason games, test on the march madness games.\n",
    "\n",
    "Of all march madness games, how many do we correctly predict?\n",
    "\"\"\"\n",
    "def evaluate_model(model, model_name):\n",
    "    is_tournament_game = lambda r : r[\"Type\"] != \"NCAA\"\n",
    "    training_set = all_games[all_games.apply(is_tournament_game, axis=1)]\n",
    "    testing_set =  all_games[~all_games.apply(is_tournament_game, axis=1)]\n",
    "\n",
    "    weights = model(training_set)\n",
    "\n",
    "    team_weights = [(team, weights[team]) for team in all_teams]\n",
    "    team_weights.sort(key = lambda x: x[1], reverse=True)\n",
    "    print(f'{model_name}, Predicted top 25 rankings of:')\n",
    "    for team,weight in team_weights[0:25]:\n",
    "        print(f'{team}: {weight}')\n",
    "\n",
    "    correct_guesses = 0\n",
    "    total_guesses = 0\n",
    "\n",
    "    for _, r in testing_set.iterrows():\n",
    "        exp_result = weights[r[\"Team\"]] > weights[r[\"Opponent\"]]\n",
    "        seen_result = r[\"For\"] > r[\"Against\"]\n",
    "        correct_guesses += exp_result == seen_result\n",
    "        total_guesses += 1\n",
    "\n",
    "\n",
    "    print(f'{model_name} predicted {correct_guesses} of {total_guesses} games correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f88aa-9f5c-4d15-a699-e73f6d25535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(parametric_estimation_prod, \"parametric estimation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e502b9-79fd-4eed-acdd-98516dde4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(higher_rank_model, \"higher rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f19a52-8eb2-4f6c-aa44-d75730f2f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(bradley_terry, \"bradley terry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245f526-4b09-417c-a803-a29f5ae3ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_reg_game = lambda r : r[\"Type\"] != \"NCAA\"\n",
    "regular_season_games = all_games[all_games.apply(is_reg_game, axis=1)]\n",
    "param_sigma, param_weights = parametric_estimation(regular_season_games)\n",
    "bt_weights = bradley_terry(regular_season_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4053c-243e-409a-9236-3f491dce7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "postseason_games = all_games[~all_games.apply(is_reg_game, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec677ed-5b86-4b17-983e-2225ca624aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import erf, sqrt\n",
    "from typing import List\n",
    "\n",
    "def expected_result(team1: int, team2: int, sigma: float, strengths: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    give the probability that team1 beats team2\n",
    "    \"\"\"\n",
    "    diff = strengths[team1] - strengths[team2]\n",
    "    \n",
    "    # Compute the probability using the CDF of the normal distribution\n",
    "    # P(team1 beats team2) = P(D > 0), where D ~ N(diff, sigma^2)\n",
    "    # Standardize the difference for the normal distribution\n",
    "    z = diff / (sigma * sqrt(2))\n",
    "    \n",
    "    # Use the error function to compute the CDF\n",
    "    prob = 0.5 * (1 + erf(z))\n",
    "    \n",
    "    return prob\n",
    "\n",
    "\n",
    "bradley_terry_confidence = lambda team1,team2 : bt_weights[team1] / (bt_weights[team1] + bt_weights[team2])\n",
    "param_confidence = lambda team1, team2 : expected_result(team1, team2, param_sigma, param_weights)\n",
    "ranking_confidence = lambda team1, team2 : 1 if team_ranking.get(team1, 0) > team_ranking.get(team2, 0) else 0\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def total_log_loss(all_games, probability_lambda):\n",
    "    log_loss = 0.0\n",
    "\n",
    "    for _, game in all_games.iterrows():\n",
    "        team1 = game[\"Team\"]\n",
    "        team2 = game[\"Opponent\"]\n",
    "        actual_outcome = 1 if game[\"For\"] > game[\"Against\"] else 0  # 1 if team1 wins, 0 otherwise\n",
    "        \n",
    "        # Get the predicted probability that team1 wins\n",
    "        predicted_prob = probability_lambda(team1, team2)\n",
    "        \n",
    "        # Ensure probabilities are within a safe range to avoid math errors\n",
    "        predicted_prob = np.clip(predicted_prob, 1e-15, 1 - 1e-15)\n",
    "        \n",
    "        # Compute the log loss for this game\n",
    "        log_loss += - (actual_outcome * np.log(predicted_prob) + (1 - actual_outcome) * np.log(1 - predicted_prob))\n",
    "    \n",
    "    return -log_loss / all_games.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145abf33-3bdd-4dec-a339-95b06233e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_loss = total_log_loss(postseason_games, bradley_terry_confidence)\n",
    "param_loss = total_log_loss(postseason_games, param_confidence)\n",
    "\n",
    "\n",
    "print(f'bt loss: {bt_loss}')\n",
    "print(f'param loss: {param_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb960c-e984-4e0f-9ccf-349bf6e9b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clip = 10\n",
    "Function 'pairwise_strength_eval' took 10.5640 seconds\n",
    "pairwise strength, Predicted top 25 rankings of:\n",
    "McNeese State: 1009.0\n",
    "James Madison: 969.0\n",
    "Connecticut: 957.0\n",
    "Grand Canyon: 873.0\n",
    "North Carolina: 873.0\n",
    "Purdue: 861.0\n",
    "Houston: 849.0\n",
    "Auburn: 849.0\n",
    "Duke: 845.0\n",
    "New Mexico: 773.0\n",
    "Iowa State: 761.0\n",
    "Gonzaga: 753.0\n",
    "Samford: 753.0\n",
    "Arizona: 721.0\n",
    "Morehead State: 705.0\n",
    "Illinois: 701.0\n",
    "Colorado State: 697.0\n",
    "Drake: 681.0\n",
    "Florida Atlantic: 653.0\n",
    "Vermont: 653.0\n",
    "Dayton: 629.0\n",
    "College of Charleston: 629.0\n",
    "Saint Mary's (CA): 621.0\n",
    "Nevada: 609.0\n",
    "Tennessee: 609.0\n",
    "pairwise strength predicted 39 of 71 games correctly\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c23d19-c817-4d50-b00b-db6cd655b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Skill vs. luck table.\n",
    "\n",
    "Each point (x,y) represents the (win % in the first half of the season, win % in second half)\n",
    "\n",
    "Regular season start: November 6, 2023\n",
    "Regular season end: March 9, 2023\n",
    "Regular season middle point: January 7, 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1d80f-778b-407d-a36f-8080890e91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "teams = all_teams\n",
    "\n",
    "def team_win_pct(games, team_set):\n",
    "    team_w, team_l = defaultdict(lambda: 0), defaultdict(lambda: 1)\n",
    "    for _, g in games.iterrows():\n",
    "        if g[\"For\"] > g[\"Against\"]:\n",
    "            team_w[g[\"Team\"]] += 1\n",
    "            team_l[g[\"Opponent\"]] += 1\n",
    "        else:\n",
    "            team_w[g[\"Opponent\"]] += 1\n",
    "            team_l[g[\"Team\"]] += 1\n",
    "    return {team: team_w[team] / (team_w[team] + team_l[team]) for team in team_set}\n",
    "def team_split_win_pct(games, team_set):\n",
    "    cutoff_date = pd.Timestamp('2024-01-07')\n",
    "    \n",
    "    after_cutoff = games[games[\"Date\"] >= cutoff_date]\n",
    "    before_cutoff = games[games[\"Date\"] < cutoff_date]\n",
    "\n",
    "    before_cutoff_pct = team_win_pct(before_cutoff, team_set)\n",
    "    after_cutoff_pct = team_win_pct(after_cutoff, team_set)\n",
    "\n",
    "    return {team : (before_cutoff_pct[team], after_cutoff_pct[team])\n",
    "            for team in before_cutoff_pct.keys() & after_cutoff_pct.keys()}\n",
    "def compute_line_endpoints(length: float, offset: Tuple[float, float], rotation: float) -> Tuple[Tuple[float, float], Tuple[float, float]]:\n",
    "    x_center, y_center = offset\n",
    "\n",
    "    half_length = length / 2\n",
    "\n",
    "    direction_x = half_length * np.cos(rotation)\n",
    "    direction_y = half_length * np.sin(rotation)\n",
    "    point1 = (x_center - direction_x, y_center - direction_y)\n",
    "    point2 = (x_center + direction_x, y_center + direction_y)\n",
    "\n",
    "    return point1, point2  \n",
    "    \n",
    "team_win_pcts = team_split_win_pct(all_games, ranked_teams)\n",
    "data_points = np.array([v for v in team_win_pcts.values()])\n",
    "\n",
    "x,y = zip(*team_win_pcts.values())\n",
    "\n",
    "\n",
    "# Transform (x, y) to (S, T) and compute the variance along these axes\n",
    "theta = np.radians(45)\n",
    "\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), np.sin(theta)],\n",
    "    [-np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "S, T = np.dot(data_points, rotation_matrix.T).T\n",
    "\n",
    "var_S = np.var(S)  \n",
    "var_T = np.var(T)  \n",
    "\n",
    "S_line_x, S_line_y = zip(compute_line_endpoints(length=.5, offset=(.9,.2), rotation=np.pi/4))\n",
    "T_line_x, T_line_y = zip(compute_line_endpoints(length=.2, offset=(.9,.9), rotation=(5*np.pi /4)))\n",
    "\n",
    "plt.plot(S_line_x, S_line_y, label = \"A = var(S)\")\n",
    "plt.plot(T_line_x, T_line_y, label = \"B = var(T)\")\n",
    "\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(x, y, color='blue')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"First Half Win Percent\")\n",
    "plt.ylabel(\"Second Half Win Percent\")\n",
    "plt.plot([0,1],[0,1], color=\"black\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "var_S, var_T\n",
    "R = 1 - (var_T/var_S)\n",
    "var_S, var_T, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8fcc9-61cc-4e99-bc77-1d5b50b1042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For models: mean binary cross-entropy loss\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
